{
 "cells": [
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-22T19:37:20.124257Z",
     "start_time": "2025-04-22T19:34:45.405673Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import spacy\n",
    "from spacy.tokens import DocBin\n",
    "\n",
    "def dataset_stats(spacy_paths, lang=\"uk\"):\n",
    "    # load blank model and add a sentencizer\n",
    "    nlp = spacy.blank(lang)\n",
    "    nlp.add_pipe(\"sentencizer\")\n",
    "    \n",
    "    total_words = 0\n",
    "    total_sentences = 0\n",
    "\n",
    "    for path in spacy_paths:\n",
    "        docbin = DocBin().from_disk(path)\n",
    "        for doc in docbin.get_docs(nlp.vocab):\n",
    "            # count tokens in the original Doc\n",
    "            total_words += len(doc)\n",
    "            # run sentencizer on its text to count sentences\n",
    "            doc_with_sents = nlp(doc.text)\n",
    "            total_sentences += len(list(doc_with_sents.sents))\n",
    "\n",
    "    return total_words, total_sentences\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    files = [\"silver_spacy/UberNER1.spacy\", \"silver_spacy/UberNER2.spacy\"]\n",
    "    words, sentences = dataset_stats(files, lang=\"uk\")\n",
    "    print(f\"Total words: {words}\")\n",
    "    print(f\"Total sentences: {sentences}\")"
   ],
   "id": "c8e9921cf648eeaf",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total words: 45489533\n",
      "Total sentences: 2573205\n"
     ]
    }
   ],
   "execution_count": 3
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-22T19:25:50.815769Z",
     "start_time": "2025-04-22T19:24:37.685065Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import spacy\n",
    "from spacy.tokens import DocBin\n",
    "from collections import Counter, defaultdict\n",
    "\n",
    "def entity_distribution(spacy_paths, lang=\"uk\"):\n",
    "    nlp = spacy.blank(lang)\n",
    "    total_counts = Counter()\n",
    "    unique_entities = defaultdict(set)\n",
    "\n",
    "    for path in spacy_paths:\n",
    "        docbin = DocBin().from_disk(path)\n",
    "        for doc in docbin.get_docs(nlp.vocab):\n",
    "            for ent in doc.ents:\n",
    "                total_counts[ent.label_] += 1\n",
    "                unique_entities[ent.label_].add(ent.text)\n",
    "\n",
    "    return total_counts, unique_entities\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    files = [\"silver_spacy/UberNER1.spacy\", \"silver_spacy/UberNER2.spacy\"]\n",
    "    counts, uniques = entity_distribution(files, lang=\"uk\")\n",
    "\n",
    "    print(\"Label     Total Occurrences   Unique Texts\")\n",
    "    print(\"-----     -----------------   ------------\")\n",
    "    for label, freq in counts.most_common():\n",
    "        uniq_count = len(uniques[label])\n",
    "        print(f\"{label:10} {freq:18}   {uniq_count}\")\n",
    "\n",
    "    overall_unique = sum(len(texts) for texts in uniques.values())\n",
    "    print(f\"\\nOverall distinct entity texts: {overall_unique}\")\n"
   ],
   "id": "679577326796e5e9",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Label     Total Occurrences   Unique Texts\n",
      "-----     -----------------   ------------\n",
      "LOC                   1655906   90676\n",
      "ORG                    866186   153999\n",
      "PERS                   572179   127690\n",
      "JOB                    542881   46418\n",
      "DATE                   210526   22679\n",
      "MISC                   136276   36232\n",
      "ART                    129478   31578\n",
      "PERIOD                 126979   23839\n",
      "MON                     87102   34095\n",
      "QUANT                   49024   18100\n",
      "PCT                     46694   6180\n",
      "TIME                    39236   5307\n",
      "DOC                     30849   17272\n",
      "\n",
      "Overall distinct entity texts: 614065\n"
     ]
    }
   ],
   "execution_count": 2
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-23T08:23:58.259686Z",
     "start_time": "2025-04-23T08:23:38.355924Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import spacy\n",
    "from spacy.tokens import DocBin\n",
    "from collections import Counter, defaultdict\n",
    "\n",
    "def entity_distribution(spacy_paths, lang=\"uk\"):\n",
    "    nlp = spacy.blank(lang)\n",
    "    total_counts = Counter()\n",
    "    unique_entities = defaultdict(set)\n",
    "\n",
    "    for path in spacy_paths:\n",
    "        docbin = DocBin().from_disk(path)\n",
    "        for doc in docbin.get_docs(nlp.vocab):\n",
    "            for ent in doc.ents:\n",
    "                total_counts[ent.label_] += 1\n",
    "                unique_entities[ent.label_].add(ent.text)\n",
    "\n",
    "    return total_counts, unique_entities\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    files = [\"silver_spacy/trimmed_UberNER.spacy\"]\n",
    "    counts, uniques = entity_distribution(files, lang=\"uk\")\n",
    "\n",
    "    print(\"Label     Total Occurrences   Unique Texts\")\n",
    "    print(\"-----     -----------------   ------------\")\n",
    "    for label, freq in counts.most_common():\n",
    "        uniq_count = len(uniques[label])\n",
    "        print(f\"{label:10} {freq:18}   {uniq_count}\")\n",
    "\n",
    "    overall_unique = sum(len(texts) for texts in uniques.values())\n",
    "    print(f\"\\nOverall distinct entity texts: {overall_unique}\")"
   ],
   "id": "6142c755b1d8be5",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Label     Total Occurrences   Unique Texts\n",
      "-----     -----------------   ------------\n",
      "LOC                    477252   89334\n",
      "ORG                    353458   151260\n",
      "PERS                   246840   126325\n",
      "JOB                    208195   46194\n",
      "DATE                    78427   22380\n",
      "MISC                    58477   33352\n",
      "MON                     56402   34016\n",
      "ART                     55929   29538\n",
      "PERIOD                  48957   23269\n",
      "QUANT                   29848   18016\n",
      "DOC                     21806   17046\n",
      "PCT                     18390   6112\n",
      "TIME                    16250   5148\n",
      "\n",
      "Overall distinct entity texts: 601990\n"
     ]
    }
   ],
   "execution_count": 1
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-21T19:55:31.328314Z",
     "start_time": "2025-04-21T19:54:22.304857Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import spacy\n",
    "from spacy.tokens import DocBin\n",
    "from collections import Counter\n",
    "\n",
    "def entity_distribution(spacy_paths, lang=\"uk\"):\n",
    "    nlp = spacy.blank(lang)\n",
    "    total_counts = Counter()\n",
    "    for path in spacy_paths:\n",
    "        docbin = DocBin().from_disk(path)\n",
    "        for doc in docbin.get_docs(nlp.vocab):\n",
    "            for ent in doc.ents:\n",
    "                total_counts[ent.label_] += 1\n",
    "    return total_counts\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    files = [\"silver_spacy/UberNER1.spacy\", \"silver_spacy/UberNER2.spacy\"]\n",
    "    dist = entity_distribution(files, lang=\"uk\")\n",
    "    print(\"Combined entity distribution:\")\n",
    "    for label, freq in dist.most_common():\n",
    "        print(f\"{label:10} {freq}\")"
   ],
   "id": "6cec703ff648d122",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Combined entity distribution:\n",
      "LOC        1655906\n",
      "ORG        866186\n",
      "PERS       572179\n",
      "JOB        542881\n",
      "DATE       210526\n",
      "MISC       136276\n",
      "ART        129478\n",
      "PERIOD     126979\n",
      "MON        87102\n",
      "QUANT      49024\n",
      "PCT        46694\n",
      "TIME       39236\n",
      "DOC        30849\n"
     ]
    }
   ],
   "execution_count": 2
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-22T08:31:01.654231Z",
     "start_time": "2025-04-22T08:30:23.746793Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import spacy\n",
    "from spacy.tokens import DocBin\n",
    "from collections import Counter\n",
    "\n",
    "def entity_distribution(spacy_paths, lang=\"uk\"):\n",
    "    nlp = spacy.blank(lang)\n",
    "    total_counts = Counter()\n",
    "    for path in spacy_paths:\n",
    "        docbin = DocBin().from_disk(path)\n",
    "        for doc in docbin.get_docs(nlp.vocab):\n",
    "            for ent in doc.ents:\n",
    "                total_counts[ent.label_] += 1\n",
    "    return total_counts\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    files = [\"silver_spacy/UberNER1.spacy\"]\n",
    "    dist = entity_distribution(files, lang=\"uk\")\n",
    "    print(\"Combined entity distribution:\")\n",
    "    for label, freq in dist.most_common():\n",
    "        print(f\"{label:10} {freq}\")"
   ],
   "id": "63a6a3c8bcb9c521",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Combined entity distribution:\n",
      "LOC        901057\n",
      "ORG        467809\n",
      "PERS       308641\n",
      "JOB        292915\n",
      "DATE       114050\n",
      "MISC       73866\n",
      "ART        70118\n",
      "PERIOD     68921\n",
      "MON        46533\n",
      "QUANT      26368\n",
      "PCT        24953\n",
      "TIME       21449\n",
      "DOC        16629\n"
     ]
    }
   ],
   "execution_count": 3
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-22T08:31:33.215008Z",
     "start_time": "2025-04-22T08:31:01.656988Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import spacy\n",
    "from spacy.tokens import DocBin\n",
    "from collections import Counter\n",
    "\n",
    "def entity_distribution(spacy_paths, lang=\"uk\"):\n",
    "    nlp = spacy.blank(lang)\n",
    "    total_counts = Counter()\n",
    "    for path in spacy_paths:\n",
    "        docbin = DocBin().from_disk(path)\n",
    "        for doc in docbin.get_docs(nlp.vocab):\n",
    "            for ent in doc.ents:\n",
    "                total_counts[ent.label_] += 1\n",
    "    return total_counts\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    files = [\"silver_spacy/UberNER2.spacy\"]\n",
    "    dist = entity_distribution(files, lang=\"uk\")\n",
    "    print(\"Combined entity distribution:\")\n",
    "    for label, freq in dist.most_common():\n",
    "        print(f\"{label:10} {freq}\")"
   ],
   "id": "8e991c527f882f68",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Combined entity distribution:\n",
      "LOC        754849\n",
      "ORG        398377\n",
      "PERS       263538\n",
      "JOB        249966\n",
      "DATE       96476\n",
      "MISC       62410\n",
      "ART        59360\n",
      "PERIOD     58058\n",
      "MON        40569\n",
      "QUANT      22656\n",
      "PCT        21741\n",
      "TIME       17787\n",
      "DOC        14220\n"
     ]
    }
   ],
   "execution_count": 4
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-23T10:22:54.319884Z",
     "start_time": "2025-04-23T10:21:37.263758Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import spacy\n",
    "from spacy.tokens import DocBin\n",
    "from collections import Counter, defaultdict\n",
    "\n",
    "def top_entities(spacy_paths, lang=\"uk\", top_n=5):\n",
    "    # blank model just for vocab\n",
    "    nlp = spacy.blank(lang)\n",
    "    freqs = defaultdict(Counter)\n",
    "\n",
    "    # count each entity text per label\n",
    "    for path in spacy_paths:\n",
    "        docbin = DocBin().from_disk(path)\n",
    "        for doc in docbin.get_docs(nlp.vocab):\n",
    "            for ent in doc.ents:\n",
    "                freqs[ent.label_][ent.text] += 1\n",
    "\n",
    "    # select top N for each label\n",
    "    top_per_label = {\n",
    "        label: counter.most_common(top_n)\n",
    "        for label, counter in freqs.items()\n",
    "    }\n",
    "    return top_per_label\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    files = [\"silver_spacy/UberNER1.spacy\", \"silver_spacy/UberNER2.spacy\"]\n",
    "    top5 = top_entities(files, lang=\"uk\", top_n=5)\n",
    "\n",
    "    for label, items in top5.items():\n",
    "        print(f\"{label}:\")\n",
    "        for text, count in items:\n",
    "            print(f\"  {text} — {count}\")"
   ],
   "id": "8d7822a8a86dbb1b",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ORG:\n",
      "  ЗСУ — 34039\n",
      "  ЄС — 16887\n",
      "  НАТО — 14430\n",
      "  СБУ — 11718\n",
      "  ДСНС — 9327\n",
      "PERIOD:\n",
      "  добу — 10296\n",
      "  минулу добу — 5218\n",
      "  місяць — 2534\n",
      "  тиждень — 1837\n",
      "  рік — 1777\n",
      "JOB:\n",
      "  голова — 14621\n",
      "  військові — 9928\n",
      "  президент — 9184\n",
      "  президента — 8832\n",
      "  Президент — 6981\n",
      "MISC:\n",
      "  COVID-19 — 14177\n",
      "  АТО — 1661\n",
      "  ООС — 1201\n",
      "  Другої світової війни — 1187\n",
      "  БПЛА — 1011\n",
      "PCT:\n",
      "  50 % — 1586\n",
      "  100 % — 1487\n",
      "  80 % — 1374\n",
      "  20 % — 1329\n",
      "  30 % — 1275\n",
      "LOC:\n",
      "  України — 129760\n",
      "  Україні — 89447\n",
      "  США — 34284\n",
      "  Україна — 32719\n",
      "  Україну — 31277\n",
      "PERS:\n",
      "  Володимир Зеленський — 11081\n",
      "  Зеленський — 9817\n",
      "  Зеленського — 7478\n",
      "  Путіна — 6240\n",
      "  Путін — 4708\n",
      "DATE:\n",
      "  24 лютого — 3262\n",
      "  сьогодні — 2609\n",
      "  2014 році — 1858\n",
      "  2014 року — 1609\n",
      "  2021 році — 1596\n",
      "QUANT:\n",
      "  120 мм — 358\n",
      "  15 - 20 м / с — 296\n",
      "  155 мм — 283\n",
      "  барель — 272\n",
      "  га — 249\n",
      "TIME:\n",
      "  18:00 — 952\n",
      "  12:00 — 886\n",
      "  9:00 — 858\n",
      "  18.00 — 819\n",
      "  06.00 — 808\n",
      "DOC:\n",
      "  Кримінального кодексу України — 1005\n",
      "  КК України — 379\n",
      "  Конституції — 350\n",
      "  Конституції України — 319\n",
      "  ККУ — 290\n",
      "ART:\n",
      "  HIMARS — 1315\n",
      "  С-300 — 1292\n",
      "  Орлан-10 — 1241\n",
      "  Калібр — 1231\n",
      "  Су-25 — 1153\n",
      "MON:\n",
      "  EUR — 1192\n",
      "  USD — 1168\n",
      "  100 млн грн — 177\n",
      "  100 тисяч гривень — 169\n",
      "  $ 1 млрд — 168\n"
     ]
    }
   ],
   "execution_count": 2
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "",
   "id": "72020e90c6e64c11"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
