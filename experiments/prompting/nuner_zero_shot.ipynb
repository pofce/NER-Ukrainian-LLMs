{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "KeBDnZK9KHcz"
   },
   "outputs": [],
   "source": [
    "%%capture\n",
    "!pip install gradio\n",
    "!pip install accelerate -U\n",
    "!pip install transformers huggingface_hub\n",
    "!pip install gliner[gpu]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5d597a42b4294d9c855fd4235a2504ab",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Fetching 7 files:   0%|          | 0/7 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "72735bc4df3845d29f2b26085381ca91",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model.safetensors:   0%|          | 0.00/1.80G [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "075b272000a944bf89c9f45972aa62ce",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "pytorch_model.bin:   0%|          | 0.00/1.80G [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "300728364e8e4d0c828915d6aeead293",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "README.md:   0%|          | 0.00/4.06k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7e4ce4e7715142738b2583c3db490e25",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "zero_shot_performance_unzero_token.png:   0%|          | 0.00/43.1k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2b0d520592384f199c5c947393921b01",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       ".gitattributes:   0%|          | 0.00/1.52k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e1a4e9bf61e5476088a2222ddd4de605",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "gliner_config.json:   0%|          | 0.00/634 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e6ddafecb67449ea8d79600f34fd9d66",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "NuZero_token_token_metrics.txt:   0%|          | 0.00/961 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "56a73a8fe79b475ebf2fdbcab4a030dc",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer_config.json:   0%|          | 0.00/52.0 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "de35cf9748d946508a78c8f589c16566",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "config.json:   0%|          | 0.00/580 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4f7533ef91b742d1b36796bf72ab7dce",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "spm.model:   0%|          | 0.00/2.46M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/venv/main/lib/python3.10/site-packages/transformers/convert_slow_tokenizer.py:559: UserWarning: The sentencepiece tokenizer that you are converting to a fast tokenizer uses the byte fallback option which is not implemented in the fast tokenizers. In practice this means that the fast version of the tokenizer can produce unknown tokens whereas the sentencepiece version would have converted these unknown tokens into a sequence of byte tokens matching the original piece of text.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "from gliner import GLiNER\n",
    "import torch\n",
    "\n",
    "if torch.cuda.is_available():\n",
    "    device = 'cuda'\n",
    "else:\n",
    "    device = 'cpu'\n",
    "\n",
    "print(device)\n",
    "\n",
    "model = GLiNER.from_pretrained(\"numind/NuNER_Zero\").to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "label_mapping = {\n",
    "    \"ORG\": \"organization\",\n",
    "    \"PERS\": \"person\",\n",
    "    \"LOC\": \"location\",\n",
    "    \"MON\": \"monetary value\",\n",
    "    \"PCT\": \"percentage\",\n",
    "    \"DATE\": \"date\",\n",
    "    \"TIME\": \"timestamp\",\n",
    "    \"PERIOD\": \"time period\",\n",
    "    \"JOB\": \"job title\",\n",
    "    \"DOC\": \"document name\",\n",
    "    \"QUANT\": \"quantity\",\n",
    "    \"ART\": \"artifact\",\n",
    "    \"MISC\": \"miscellaneous\"\n",
    "}\n",
    "\n",
    "labels = list(label_mapping.values())\n",
    "reverse_label_mapping = {v: k for k, v in label_mapping.items()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def merge_entities(entities):\n",
    "    if not entities:\n",
    "        return []\n",
    "    merged = []\n",
    "    current = entities[0]\n",
    "    for next_entity in entities[1:]:\n",
    "        if next_entity['label'] == current['label'] and (next_entity['start'] == current['end'] + 1 or next_entity['start'] == current['end']):\n",
    "            current['text'] = text[current['start']: next_entity['end']].strip()\n",
    "            current['end'] = next_entity['end']\n",
    "        else:\n",
    "            merged.append(current)\n",
    "            current = next_entity\n",
    "    # Append the last entity\n",
    "    merged.append(current)\n",
    "    return merged"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Asking to truncate to max_length but no maximum length is provided and the model has no predefined maximum length. Default to no truncation.\n",
      "100%|██████████| 5087/5087 [01:16<00:00, 66.86it/s]\n"
     ]
    }
   ],
   "source": [
    "from tqdm import tqdm\n",
    "import pandas as pd\n",
    "import json\n",
    "\n",
    "df = pd.read_csv(\"test.csv\")\n",
    "\n",
    "results = []\n",
    "for index, row in tqdm(df.iterrows(), total=df.shape[0]):\n",
    "    _, text, _ = row\n",
    "    entities = model.predict_entities(text, labels)\n",
    "\n",
    "    entities = merge_entities(entities)\n",
    "    \n",
    "    formatted_entities = [{\n",
    "        \"label\": reverse_label_mapping[ent[\"label\"]], \n",
    "        \"text\": ent[\"text\"],\n",
    "        \"start\": ent[\"start\"],\n",
    "        \"end\": ent[\"end\"]\n",
    "    } for ent in entities]\n",
    "    \n",
    "    results.append(json.dumps(formatted_entities, ensure_ascii=False))\n",
    "    \n",
    "df[\"pred\"] = results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_csv(\"NuNER_Zero.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "gpuType": "T4",
   "machine_shape": "hm",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
