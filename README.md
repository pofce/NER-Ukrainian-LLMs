# Improving Named Entity Recognition for Low-Resource Languages Using Large Language Models: A Ukrainian Case Study

This repository contains experiments and evaluation pipelines for Named Entity Recognition (NER) on Ukrainian texts using large language models (LLMs). It supports fine-tuning, prompting, and post-processing for various LLMs, with a focus on low-resource language scenarios.

## ğŸ“ Project Structure

```
NER-Ukrainian-LLMs/
â”‚
â”œâ”€â”€ data/                            # Raw and processed datasets
â”‚   â”œâ”€â”€ bruk/                        # BRUK part of corpus 
â”‚   â”œâ”€â”€ dev-test-split/              # Dev/test partitions
â”‚   â”œâ”€â”€ ng/                          # NG part of corpus 
â”‚   â”œâ”€â”€ train.csv|iob|spacy          # Train sets in various formats
â”‚   â””â”€â”€ test.csv|iob|spacy           # Test sets in various formats
â”‚
â”œâ”€â”€ experiments/                     # Model training and evaluation pipelines
â”‚   â”œâ”€â”€ encoders_tuning/             # Transformer encoder-only fine-tuning + evaluation
â”‚   â”œâ”€â”€ prompting/                   # Prompting-based methods experiments
â”‚   â”œâ”€â”€ sft/                         # Supervised fine-tuning experiments
â”‚   â””â”€â”€ eda.ipynb                    # Exploratory data analysis
â”‚
â”œâ”€â”€ results/
â”‚   â”œâ”€â”€ prompting/
â”‚   â”‚    â”œâ”€â”€ bronze/                 # Raw outputs
â”‚   â”‚    â”‚   â”œâ”€â”€ cot/                
â”‚   â”‚    â”‚   â”œâ”€â”€ few_shot/
â”‚   â”‚    â”‚   â””â”€â”€ zero_shot/
â”‚   â”‚    â”œâ”€â”€ silver/                 # Lightly cleaned outputs
â”‚   â”‚    â”‚   â”œâ”€â”€ cot/
â”‚   â”‚    â”‚   â”œâ”€â”€ few_shot/
â”‚   â”‚    â”‚   â””â”€â”€ zero_shot/
â”‚   â”‚    â””â”€â”€ gold/                   # Fully cleaned and rule-filtered outputs
â”‚   â”‚        â”œâ”€â”€ cot/
â”‚   â”‚        â”œâ”€â”€ few_shot/
â”‚   â”‚        â””â”€â”€ zero_shot/
â”‚   â””â”€â”€ sft/                         # Supervised fine-tuning results
â”‚
â”œâ”€â”€ utils/                           # Utility scripts
â”‚   â”œâ”€â”€ ner_eval.py                  # Evaluation metrics
â”‚   â”œâ”€â”€ basic_post_processing.py     # Silver level transformations
â”‚   â”œâ”€â”€ advanced_post_processing.py  # Gold level transformations
â”‚   â”œâ”€â”€ parse_input_to_csv.py        # Input format converter
â”‚   â””â”€â”€ __init__.py
â”‚
â”œâ”€â”€ .env                             # Environment variables (create your own)
â”œâ”€â”€ .gitignore                 
â””â”€â”€ README.md                        # Project documentation
```

---

## âš™ï¸ Repo Setup

1. Clone the repo:

```bash
git clone <repo-url>
cd NER-Ukrainian-LLMs
```

2. Install dependencies:

```bash
pip install -r requirements.txt
```

3. Set up your `.env` file.

---

## ğŸ§ª Experiments

### ğŸ”¹ Encoder-Only Models

Located in `experiments/encoders_tuning/`. Includes fine-tuning transformer-based encoders like `roberta-large`.

### ğŸ”¹ Prompt-Based

Located in `experiments/prompting/`. Inference is done using zero-shot, few-shot, or chain-of-thought (CoT) prompts. Results are post-processed using Bronze/Silver/Gold strategies.

### ğŸ”¹ Supervised Fine-Tuning (SFT)

Located in `experiments/sft/`. Full fine-tuning of LLMs using labeled training data.

---
